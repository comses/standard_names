#! /bin/env python

"""
Some URLs to scrape:
    http://csdms.colorado.edu/wiki/CSN_Quantity_Templates
    http://csdms.colorado.edu/wiki/CSN_Object_Templates
    http://csdms.colorado.edu/wiki/CSN_Operation_Templates
"""

import os
import re
import urllib

from standard_names import FORMATTERS, scrape_url
as_yaml = FORMATTERS['yaml']

def main ():
    import argparse

    parser = argparse.ArgumentParser ("Scrape standard names from a URL")
    parser.add_argument ('url', nargs='+', metavar='URL', help="URL to scrape")

    args = parser.parse_args ()

    pages = {}
    for url in args.url:
        pages[url] = scrape_url (url)

    documents = []
    for (k, v) in pages.items ():
        documents.append (os.linesep.join ([
            'model name: %s' % k,
            as_yaml (v, sorted=True, heading='exchange items')
        ]))

    docsep = os.linesep + '---' + os.linesep

    print '%YAML 1.2'
    print '---'
    print docsep.join (documents)
    print '...'

if __name__ == '__main__':
    main ()
